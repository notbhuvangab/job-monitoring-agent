# Job Monitoring Backend

FastAPI-based backend for the Job Monitoring & Resume Fit Agent.

## ğŸ—ï¸ Architecture

```
main.py                      # FastAPI application entry point
â”‚
â”œâ”€â”€ api/                     # API layer
â”‚   â”œâ”€â”€ routes.py           # REST endpoints
â”‚   â””â”€â”€ websocket_manager.py # WebSocket connections
â”‚
â”œâ”€â”€ services/                # Business logic
â”‚   â”œâ”€â”€ job_fetcher.py      # Fetch jobs from sources
â”‚   â”œâ”€â”€ job_normalizer.py   # Normalize job data
â”‚   â”œâ”€â”€ resume_parser.py    # Parse resumes
â”‚   â”œâ”€â”€ job_scorer.py       # Score jobs vs resume
â”‚   â”œâ”€â”€ job_classifier.py   # Classify by score
â”‚   â””â”€â”€ embeddings.py       # Generate embeddings
â”‚
â”œâ”€â”€ pipeline/                # Orchestration
â”‚   â””â”€â”€ langgraph_pipeline.py # LangGraph state machine
â”‚
â”œâ”€â”€ models.py                # SQLAlchemy models
â”œâ”€â”€ schemas.py               # Pydantic schemas
â”œâ”€â”€ database.py              # Database setup
â”œâ”€â”€ config.py                # Configuration
â”œâ”€â”€ scheduler.py             # APScheduler jobs
â””â”€â”€ utils/                   # Utilities
    â””â”€â”€ logger.py           # Logging
```

## ğŸš€ Quick Start

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure
cp env_example.txt .env
# Edit .env with your settings

# Run
python main.py
```

## ğŸ“¦ Dependencies

- **fastapi**: Web framework
- **uvicorn**: ASGI server
- **sqlalchemy**: ORM
- **pydantic**: Data validation
- **apscheduler**: Task scheduling
- **langchain/langgraph**: Orchestration
- **sentence-transformers**: Local embeddings
- **openai**: Optional cloud embeddings
- **pypdf2**: PDF parsing
- **scikit-learn**: Cosine similarity
- **pytest**: Testing

## ğŸ”Œ API Endpoints

### Jobs
```
GET  /api/jobs              # List jobs with filters
GET  /api/jobs/{id}         # Get specific job
GET  /api/jobs/stats/summary # Get statistics
```

### Resume
```
POST /api/resume/upload     # Upload resume
GET  /api/resume/active     # Get active resume
```

### Admin
```
POST /api/trigger-fetch     # Manual job fetch
WS   /api/ws               # WebSocket connection
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_job_scorer.py

# Run with coverage
pytest --cov=. --cov-report=html

# View coverage report
open htmlcov/index.html
```

## âš™ï¸ Configuration

Edit `.env`:

```env
# OpenAI API (optional)
OPENAI_API_KEY=sk-...

# Database
DATABASE_URL=sqlite:///./jobs.db

# Server
HOST=0.0.0.0
PORT=8000

# Scheduler
JOB_FETCH_INTERVAL_MINUTES=5

# Mock mode
USE_MOCK_DATA=true
```

## ğŸ“Š Database Schema

### Job Model
- job_id (unique)
- title, company, description
- location, type, apply_url
- status (pending/normalized/scored/classified)
- score (0-100)
- label (best/mid/least)
- embedding (JSON)
- keywords_matched (JSON)

### Resume Model
- filename, content
- skills, experiences, education (JSON)
- embedding (JSON)
- is_active (boolean)

## ğŸ”„ Pipeline Flow

1. **Fetch**: Get jobs from sources
2. **Normalize**: Standardize data format
3. **Embed**: Generate job embedding
4. **Score**: Compare with resume (cosine similarity + keywords)
5. **Classify**: Categorize by threshold
6. **Store**: Save to database
7. **Broadcast**: Notify WebSocket clients

## ğŸ“ Logging

Logs are written to:
- Console (stdout)
- `logs/app.log`

Log levels:
- INFO: Normal operations
- WARNING: Non-critical issues
- ERROR: Errors that need attention

## ğŸ” Monitoring

Check application health:
```bash
curl http://localhost:8000/api/
```

View API documentation:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ› ï¸ Development

### Add a new service

1. Create file in `services/`
2. Implement service class
3. Add to `services/__init__.py`
4. Write tests in `tests/`

### Modify scoring algorithm

Edit `services/job_scorer.py`:
```python
def score_job(job_data, resume_data, job_embedding=None):
    # Your custom scoring logic here
    pass
```

### Add new API endpoint

Edit `api/routes.py`:
```python
@router.get("/api/your-endpoint")
async def your_endpoint(db: Session = Depends(get_db)):
    # Your logic here
    pass
```

## ğŸ› Common Issues

### ImportError
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### Database locked
```bash
# Delete database and restart
rm jobs.db
python main.py
```

### Port already in use
```bash
# Change port in .env
PORT=8001
```

## ğŸ“š References

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [LangGraph Documentation](https://python.langchain.com/docs/langgraph)
- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)
- [APScheduler Documentation](https://apscheduler.readthedocs.io/)

